# -*- coding: utf-8 -*-
"""predicao_modelos_parametricos_grande_porte.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KY4VwIumR_mPjkoVkLlENWzoFVLrXvcC
"""

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import numpy as np
from statsmodels.tsa.holtwinters import SimpleExpSmoothing
import scipy.stats as stats
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.stats.stattools import durbin_watson
from statsmodels.stats.diagnostic import acorr_ljungbox
!pip install pmdarima
from pmdarima.arima import auto_arima
from statsmodels.tsa.stattools import adfuller

from google.colab import drive
drive.mount('/content/drive')

#Metodos Para Calcular o Theils U Coefficient
def division(measure, previousI):
  return measure / previousI

def power(measure):
  return np.power(measure, 2)

def summation(measure):
  return np.sum(measure)

def mean(N, measure):
  return (1/N) * measure

def sqrt(measure):
  return np.sqrt(measure)

def theil_u2(y_true, y_pred):
    y_true = np.ravel(y_true)
    y_pred = np.ravel(y_pred)
    N = len(y_true)

    subtractionNumerator = y_pred[1:] - y_true[1:]
    divisionNumerator = division(subtractionNumerator, y_true[:-1])
    powerNumerator = power(divisionNumerator)
    summationNumerator = summation(powerNumerator)
    meanNumerator = mean(N, summationNumerator)
    numerator = sqrt(meanNumerator)

    subtractionDenominator = y_true[1:] - y_true[:-1]
    powerDenominator = power(division(subtractionDenominator, y_true[:-1]))
    denominator = sqrt(mean(N, summation(powerDenominator)))

    theilU2 = numerator / denominator

    return theilU2

"""Adiciona caminho do dataset"""

dataset = pd.read_csv('/content/drive/My Drive/Projeto Internações/Preparação dos dados/dataset_internacoes_completo.csv')

dataset

dataset['populacao'].dtype

def porte(populacao):
  if populacao <= 20000:
    return 'Pequeno Porte I'
  elif populacao >= 20001 and populacao <= 50000 :
    return 'Pequeno Porte II'
  elif populacao >= 50001 and populacao <= 100000:
    return 'Médio Porte'
  elif populacao >= 100001 and populacao <= 900000:
    return 'Grande Porte'
  elif populacao >= 900001:
    return 'Metrópole'

def taxa_internacao (row):
  return row['Qtd. internacoes']*1000/row['populacao']

dataset['taxa_internacao'] = dataset.apply(taxa_internacao, axis =1)

dataset['Porte'] = dataset['populacao'].apply(porte)

dataset

"""Filtro"""

dataset = dataset[dataset['Porte'] == 'Grande Porte']

dataset

time_series = dataset[['Data completa', 'taxa_internacao']]
time_series['Data completa'] = pd.to_datetime(time_series['Data completa'])

time_series = time_series.set_index('Data completa').resample('M').mean()

time_series = time_series[:'2019-12-31']

"""#Teste de Estacionariedade

"""

X = time_series['taxa_internacao']
result = adfuller(X)
print('ADF Estatíticas: %f' % result[0])
print('Valor de P: %f' % result[1])
print('Valores Críticos:')
for key, value in result[4].items():
   print('\t%s: %.3f' % (key, value))



"""#Tornando a série estacionária (Diferenciação)"""

xdiff = X.diff()
xdiff = xdiff.dropna()
xlabel='Data'
xdiff.plot()

result = adfuller(xdiff)
print('ADF Estatíticas: %f' % result[0])
print('Valor de P: %f' % result[1])
print('Valores Críticos:')
for key, value in result[4].items():
   print('\t%s: %.3f' % (key, value))

"""#Suavização Exponencial Simples"""

X_base = X[:'2018-12-31']

X_base

suavizacao_exponencial_fit = SimpleExpSmoothing(X_base).fit(smoothing_level=0.2,optimized=False) #alpha = 0.2: 20% de peso para as observações mais recentes, optimazed: acha um valor otimizado para o smoothing_level
suavizacao_exponencial_future_forecast = suavizacao_exponencial_fit.forecast(12)

suavizacao_exponencial_future_forecast

suavizacao_exponencial_future_forecast.plot(marker='', color='blue', legend=True, label = 'Previsto')
X.plot(marker='',  color='red', label = 'Real', legend = True)
plt.show()

# Parâmetros para calcular os intervalos de confiança
alpha_95 = 0.05  # Nível de significância para intervalo de confiança de 95%
alpha_80 = 0.2
z_critical_95 = stats.norm.ppf(1 - alpha_95 / 2)  # Valor crítico para distribuição normal padrão
z_critical_80 = stats.norm.ppf(1 - alpha_80 / 2)

# Calcular intervalo de confiança
forecast_mean = suavizacao_exponencial_future_forecast  # Supondo que as previsões já foram calculadas
forecast_std = np.std(X_base)  # Desvio padrão dos dados históricos

lower_bound_95 = forecast_mean - z_critical_95 * forecast_std
upper_bound_95 = forecast_mean + z_critical_95 * forecast_std

lower_bound_80 = forecast_mean - z_critical_80 * forecast_std
upper_bound_80 = forecast_mean + z_critical_80 * forecast_std

suavizacao_exponencial_future_forecast.plot(marker='', color='blue', legend=True, label = 'Previsto')
X.plot(marker='',  color='red', label = 'Real', legend = True)

# Plotar intervalo de confiança
plt.fill_between(suavizacao_exponencial_future_forecast.index, lower_bound_95, upper_bound_95, color='gray', alpha=0.3, label='Intervalo de Confiança (95%)')
plt.fill_between(suavizacao_exponencial_future_forecast.index, lower_bound_80, upper_bound_80, color='blue', alpha=0.3, label='Intervalo de Confiança (80%)')

plt.title('Suavização Exponencial Simples com Intervalo de Confiança')

plt.show()

real = X['2019-01-01':]

real

mean_absolute_error(real, suavizacao_exponencial_future_forecast)

np.sqrt(mean_squared_error(real, suavizacao_exponencial_future_forecast))

mean_absolute_percentage_error(real, suavizacao_exponencial_future_forecast)

real

"""#SARIMA

"""

plot_acf(X)
plt.show()

plot_pacf(X, method='ywm')
plt.show()

acorr_ljungbox(X, lags=[24])

sarima_model = auto_arima(X,start_p=1, start_q=1,max_p=6, max_q=6, m=12, start_P=0, seasonal=True, d=1, D=1, trace=True, error_action='ignore',
                            suppress_warnings=True, stepwise=True)

print(sarima_model.aic())

train = X.loc[:'2018-12-31']
test = X.loc['2019-01-01':]

sarima_model.fit(train)

sarima_future_forecast = sarima_model.predict(n_periods=12)

sarima_future_forecast.index

sarima_future_forecast

sarima_future_forecast.plot(marker='', color='blue', legend=True, label='Previsto')
test.plot(marker='', color='red', label='Real', legend=True)

plt.show()

sarima_future_forecast.plot(marker='', color='blue', legend=True, label='Previsto')
X.plot(marker='', color='red', label='Real', legend=True)

plt.show()

# Parâmetros para calcular os intervalos de confiança
alpha_95 = 0.05  # Nível de significância para intervalo de confiança de 95%
alpha_80 = 0.2
z_critical_95 = stats.norm.ppf(1 - alpha_95 / 2)  # Valor crítico para distribuição normal padrão
z_critical_80 = stats.norm.ppf(1 - alpha_80 / 2)

# Calcular intervalo de confiança
forecast_mean = sarima_future_forecast  # Supondo que as previsões já foram calculadas
forecast_std = np.std(X_base)  # Desvio padrão dos dados históricos

lower_bound_95 = forecast_mean - z_critical_95 * forecast_std
upper_bound_95 = forecast_mean + z_critical_95 * forecast_std

lower_bound_80 = forecast_mean - z_critical_80 * forecast_std
upper_bound_80 = forecast_mean + z_critical_80 * forecast_std

sarima_future_forecast.index

sarima_future_forecast.plot(marker='', color='blue', legend=True, label='Previsto')
X.plot(marker='', color='red', label='Real', legend=True)

plt.title('Taxa de Internações - Sarima')
plt.ylabel('Taxa Internações')
plt.xlabel('Data')

plt.fill_between(sarima_future_forecast.index, lower_bound_95, upper_bound_95, color='gray', alpha=0.3, label='Intervalo de Confiança (95%)')
plt.fill_between(sarima_future_forecast.index, lower_bound_80, upper_bound_80, color='blue', alpha=0.3, label='Intervalo de Confiança (80%)')

# Calcular o Erro Absoluto Médio (MAE)
mae = mean_absolute_error(test,sarima_future_forecast)
print(f'MAE: {mae}')

# Calcular o Erro Quadrático Médio (MSE)
mse = mean_squared_error(test,sarima_future_forecast)
print(f'MSE: {mse}')

# Calcular a Raiz do Erro Quadrático Médio (RMSE)
rmse = np.sqrt(mse)
print(f'RMSE: {rmse}')

mape = mean_absolute_percentage_error(test,sarima_future_forecast)
print(f'MAPE: {mape}')

TU = theil_u2(test, sarima_future_forecast)
print(f'TU: {TU}')

model_fit = sarima_model.fit(train)

durbin_watson(model_fit.resid())

"""#ARIMA"""

arima_model = auto_arima(X,
                         start_p=1, start_q=1,
                         max_p=6, max_q=6,
                         seasonal=False,  # Definindo como False para um modelo ARIMA
                         d=1, D=1,
                         trace=True,
                         error_action='ignore',
                         suppress_warnings=True,
                         stepwise=True)

arima_model.fit(train)

future_forecast_arima = arima_model.predict(n_periods=12)

future_forecast_arima.index

future_forecast_arima.plot(marker='', color='blue', legend=True, label='Previsto')
test.plot(marker='', color='red', label='Real', legend=True)

plt.show()

future_forecast_arima.plot(marker='', color='blue', legend=True, label='Previsto')
X.plot(marker='', color='red', label='Real', legend=True)

plt.show()

# Parâmetros para calcular os intervalos de confiança
alpha_95 = 0.05  # Nível de significância para intervalo de confiança de 95%
alpha_80 = 0.2
z_critical_95 = stats.norm.ppf(1 - alpha_95 / 2)  # Valor crítico para distribuição normal padrão
z_critical_80 = stats.norm.ppf(1 - alpha_80 / 2)

# Calcular intervalo de confiança
forecast_mean = future_forecast_arima  # Supondo que as previsões já foram calculadas
forecast_std = np.std(X_base)  # Desvio padrão dos dados históricos

lower_bound_95 = forecast_mean - z_critical_95 * forecast_std
upper_bound_95 = forecast_mean + z_critical_95 * forecast_std

lower_bound_80 = forecast_mean - z_critical_80 * forecast_std
upper_bound_80 = forecast_mean + z_critical_80 * forecast_std

future_forecast_arima

future_forecast_arima.plot(marker='', color='blue', legend=True, label='Previsto')
X.plot(marker='', color='red', label='Real', legend=True)

plt.title('Taxa de Internações - Arima')
plt.ylabel('Taxa Internações')
plt.xlabel('Data')

plt.fill_between(future_forecast_arima.index, lower_bound_95, upper_bound_95, color='gray', alpha=0.3, label='Intervalo de Confiança (95%)')
plt.fill_between(future_forecast_arima.index, lower_bound_80, upper_bound_80, color='blue', alpha=0.3, label='Intervalo de Confiança (80%)')

# Calcular o Erro Absoluto Médio (MAE)
mae = mean_absolute_error(test,future_forecast_arima)
print(f'MAE: {mae}')

# Calcular o Erro Quadrático Médio (MSE)
mse = mean_squared_error(test,future_forecast_arima)
print(f'MSE: {mse}')

# Calcular a Raiz do Erro Quadrático Médio (RMSE)
rmse = np.sqrt(mse)
print(f'RMSE: {rmse}')

mape = mean_absolute_percentage_error(test,future_forecast_arima)
print(f'MAPE: {mape}')

TU = theil_u2(test, future_forecast_arima)
print(f'TU: {TU}')

model_fit = arima_model.fit(train)

durbin_watson(model_fit.resid())

!pip freeze > requirements.txt